# ğŸš€ Day 3 â€“ Autonomous Experiment Execution Engine

## ğŸ§  Problem Statement

Modern AI systems can generate code.

But a major limitation exists:

- AI writes code.
- Human manually runs it.
- If error occurs â†’ Human fixes prompt.
- Retry cycle is manual.
- No self-correction loop.

This creates a bottleneck in autonomous experimentation.

We needed a system that:

âœ” Generates Python code  
âœ” Executes it automatically  
âœ” Detects runtime errors  
âœ” Feeds errors back to the AI  
âœ” Retries intelligently  
âœ” Stops only after success  

In short:

We needed an **Autonomous Self-Correcting Code Execution Engine**.

---

## ğŸ¯ Objective

Build a system that can:

1. Accept a research task.
2. Ask the LLM to write Python code.
3. Execute that code dynamically.
4. Capture output or error.
5. Retry with feedback.
6. Return successful result automatically.

No human intervention.

---

## ğŸ— Architecture Overview

### ğŸ”¹ 1. Code Execution Layer

- Uses `exec()` to run dynamic Python code.
- Redirects stdout using `StringIO`.
- Captures both output and errors.
- Returns structured response.

### ğŸ”¹ 2. Autonomous Retry Loop

- Sends task to LLM.
- Runs returned code.
- If error â†’ sends error back to LLM.
- Retries up to defined limit.
- Stops when success is achieved.

### ğŸ”¹ 3. Synthetic Data Strategy

As selected earlier:
- No real-world API dependency.
- Uses synthetic data generation.
- Ensures reproducibility.
- Safe experimental environment.

---
